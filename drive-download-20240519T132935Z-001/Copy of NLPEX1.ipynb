{"cells":[{"cell_type":"code","execution_count":null,"id":"5a70acf1","metadata":{"id":"5a70acf1"},"outputs":[],"source":["# import the necessary libraries\n","import nltk\n","import string\n","import re"]},{"cell_type":"code","execution_count":null,"id":"fee47e2a","metadata":{"id":"fee47e2a","outputId":"2fe289d4-8f3d-4dbe-9296-690a7a6df5e8"},"outputs":[{"data":{"text/plain":["\"hey, did you know that the summer break is coming? amazing right !! it's only 5 more days !!\""]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["def text_lowercase(text):\n","    return text.lower()\n","\n","input_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\";\n","text_lowercase(input_str)"]},{"cell_type":"code","execution_count":null,"id":"1b3983de","metadata":{"id":"1b3983de","outputId":"1a6334c8-c4eb-4669-f9eb-5703f4f5eff4"},"outputs":[{"data":{"text/plain":["'There are  balls in this bag, and  in the other one.'"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Remove numbers\n","def remove_numbers(text):\n","\tresult = re.sub(r'\\d+', '', text)\n","\treturn result\n","\n","input_str = \"There are 3 balls in this bag, and 12 in the other one.\"\n","remove_numbers(input_str)\n"]},{"cell_type":"code","execution_count":null,"id":"defcf80d","metadata":{"id":"defcf80d","outputId":"8a3552d2-500f-4e15-f60c-9d91bbb036b8"},"outputs":[{"data":{"text/plain":["'Hey did you know that the summer break is coming Amazing right  Its only 5 more days '"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["# remove punctuation\n","def remove_punctuation(text):\n","\ttranslator = str.maketrans('', '', string.punctuation)\n","\treturn text.translate(translator)\n","input_str = \"Hey, did you know that the summer break is coming? Amazing right !! It's only 5 more days !!\"\n","remove_punctuation(input_str)\n"]},{"cell_type":"code","execution_count":null,"id":"e8b12266","metadata":{"id":"e8b12266","outputId":"914c18b1-0d62-4a75-bf13-c41f78d24466"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to\n","[nltk_data]     C:\\Users\\Prade\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Unzipping corpora\\stopwords.zip.\n"]},{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["nltk.download('stopwords')"]},{"cell_type":"code","execution_count":null,"id":"f33f46d0","metadata":{"id":"f33f46d0","outputId":"7393b2e0-e152-4e67-b703-5c7792b0e6ad"},"outputs":[{"data":{"text/plain":["['This', 'sample', 'sentence', 'going', 'remove', 'stopwords', '.']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","\n","# remove stopwords function\n","def remove_stopwords(text):\n","\tstop_words = set(stopwords.words(\"english\"))\n","\tword_tokens = word_tokenize(text)\n","\tfiltered_text = [word for word in word_tokens if word not in stop_words]\n","\treturn filtered_text\n","\n","example_text = \"This is a sample sentence and we are going to remove the stopwords from this.\"\n","remove_stopwords(example_text)\n"]},{"cell_type":"code","execution_count":null,"id":"b3fab432","metadata":{"id":"b3fab432","outputId":"59c04360-656b-4e45-92d3-ea3fa726f707"},"outputs":[{"data":{"text/plain":["['data',\n"," 'scienc',\n"," 'use',\n"," 'scientif',\n"," 'method',\n"," 'algorithm',\n"," 'and',\n"," 'mani',\n"," 'type',\n"," 'of',\n"," 'process']"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","stemmer = PorterStemmer()\n","\n","# stem words in the list of tokenized words\n","def stem_words(text):\n","\tword_tokens = word_tokenize(text)\n","\tstems = [stemmer.stem(word) for word in word_tokens]\n","\treturn stems\n","\n","text = 'data science uses scientific methods algorithms and many types of processes'\n","stem_words(text)\n"]},{"cell_type":"code","execution_count":null,"id":"d0e346b6","metadata":{"id":"d0e346b6","outputId":"6bb69456-d1c3-47a8-a6a9-dd81569ad49e"},"outputs":[{"data":{"text/plain":["['data',\n"," 'scienc',\n"," 'use',\n"," 'scientif',\n"," 'method',\n"," 'algorithm',\n"," 'and',\n"," 'mani',\n"," 'type',\n"," 'of',\n"," 'process']"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["from nltk.stem.porter import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","stemmer = PorterStemmer()\n","\n","# stem words in the list of tokenized words\n","def stem_words(text):\n","\tword_tokens = word_tokenize(text)\n","\tstems = [stemmer.stem(word) for word in word_tokens]\n","\treturn stems\n","\n","text = 'data science uses scientific methods algorithms and many types of processes'\n","stem_words(text)\n"]},{"cell_type":"code","execution_count":null,"id":"8a0a642e","metadata":{"id":"8a0a642e","outputId":"5d3b6d2c-a619-4763-ba2c-a40e9cb2d6c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["['hi hello how are you dfdfsdf']\n","['hi', 'hello', 'how', 'are', 'you', 'dfdfsdf']\n"]}],"source":["# import the existing word and sentence tokenizing\n","# libraries\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n","text = \"hi hello how are you dfdfsdf \"\n","print(sent_tokenize(text))\n","print(word_tokenize(text))\n"]},{"cell_type":"code","execution_count":null,"id":"5e1d014d","metadata":{"id":"5e1d014d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[{"file_id":"1MVSDP-yYYwkUAZ1-k_eFxnMgHTRlSHjN","timestamp":1716125297397}]}},"nbformat":4,"nbformat_minor":5}